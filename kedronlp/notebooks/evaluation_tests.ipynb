{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cdd58d",
   "metadata": {},
   "source": [
    "# Create evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d344dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"question_type\": [\n",
    "        \"Out of domain questions\",\n",
    "        \"Out of domain questions\",\n",
    "        \"In domain questions\",\n",
    "        \"In domain questions\",\n",
    "        \"Query contains named entities that should be treated in a special way\",\n",
    "        \"Query contains named entities that should be treated in a special way\",\n",
    "        \"Handle fully specified questions that might contain stop words etc.\",\n",
    "        \"Handle fully specified questions that might contain stop words etc.\",\n",
    "        \"Fully support both semantic search and lexicographical search\",\n",
    "        \"Fully support both semantic search and lexicographical search\",\n",
    "        \"Confirmation Questions [yes or no]\",\n",
    "        \"Confirmation Questions [yes or no]\",\n",
    "        \"Factoid-type Questions [what, which, when, who, how]\",\n",
    "        \"Factoid-type Questions [what, which, when, who, how]\",\n",
    "        \"List-type Questions\",\n",
    "        \"List-type Questions\",\n",
    "        \"Causal Questions [why or how]\",\n",
    "        \"Causal Questions [why or how]\",\n",
    "        \"Hypothetical Questions\",\n",
    "        \"Hypothetical Questions\",\n",
    "        \"Complex Questions\",\n",
    "        \"Complex Questions\",\n",
    "        \"Test for edge cases\",\n",
    "        \"Test for edge cases\",\n",
    "        \"Time based questions\",\n",
    "        \"Time based questions\",\n",
    "        \"Location based questions\",\n",
    "        \"Location based questions\",\n",
    "        \"Cause and effect questions\",\n",
    "        \"Cause and effect questions\",\n",
    "        \"Scenario based questions\",\n",
    "        \"Scenario based questions\",\n",
    "        \"Fact based questions\",\n",
    "        \"Fact based questions\",\n",
    "        \"Descriptive questions\",\n",
    "        \"Descriptive questions\",\n",
    "        \"Procedural questions\",\n",
    "        \"Procedural questions\",\n",
    "        \"Comparative questions\",\n",
    "        \"Comparative questions\",\n",
    "    ],\n",
    "    \"question\": [\n",
    "        \"How tall is the Golden Gate Bridge?\",\n",
    "        \"Where is the Eiffel Tower located?\",\n",
    "        \"What are the predictors of nurses' attitudes towards communication?\",\n",
    "        \"What is Autism Spectrum Disorder (ASD) characterized by?\",\n",
    "        \"What is the TT100K dataset?\",\n",
    "        \"What is the full form of EHR? / Tell me about the strenghts and limitations of EHR (Electronic Health Records)\",\n",
    "        \"Tell me about the recent neuroscience evidence to elucidate how general intelligence, g, emerges from individual differences in the network architecture of the human brain?\",\n",
    "        \"The best fit between brain traits and degrees of intelligence among mammals is reached by?\",\n",
    "        \"(Semantic query) What is intelligence?\",\n",
    "        'Lexicographical query) Which paper was published first? Title \"Fluid intelligence is related to capacity in memory as well as attention: Evidence from middle childhood and adulthood\" or \"What is theory of mind? A psychometric study of theory of mind and intelligence\"?',\n",
    "        \"Are forms of narcissism (grandiose and vulnerable) related to objective intelligence?\",\n",
    "        \"For children who participated in a task-switching experiment, where the children performed a task repeatedly (single-trial blocks) or switched between two different tasks (mixed-trial blocks), did intellectually gifted children perform quicker than the average group for both mixed and single-trial blocks?\",\n",
    "        \"What is the Flynn Effect, and how does it change our understanding of IQ?\",\n",
    "        \"How is emotional exhaustion related to burnout?\",\n",
    "        \"List the different types of intelligence?\",\n",
    "        \"List some abreivations used in the field of intelligence in PubMed\",\n",
    "        \"Why Did Cephalopods Evolve Intelligence?\",\n",
    "        \"Why is intelligence associated with stability of happiness?\",\n",
    "        \"What would happen if there was a direct link between diet and cognitive performance in old age?\",\n",
    "        \"What would happen if business intelligence was used to manage supply costs?\",\n",
    "        \"What themes emerged in the study of the use of emotional intelligence capabilities in clinical reasoning and decision-making?\",\n",
    "        \"What tools and methods were employed in the study of the relationship between intellectual development and intrinsic motivation?\",\n",
    "        \"Jochen Kruppa, Yufeng Liu, Gérard Biau, Michael Kohler, Inke R. König, James D. Malley, and Andreas Ziegle\",\n",
    "        \"sdkfjasdkjfhasdkjfhaskjdfh\",\n",
    "        'When was the paper \"On the visual analytic intelligence of neural networks\" published?',\n",
    "        'When was the paper \"The neuroscience of empathy and compassion in pro-social behavior\" published?',\n",
    "        \"In which country is the Individuals with Disabilities Education Act (IDEA) located?\",\n",
    "        \"Fill in the blank: Impact of Artificial Intelligence on Regional Green Development under _____'s Environmental Decentralization System-Based on Spatial Durbin Model and Threshold Effect\",\n",
    "        \"What are the causes of international differences in student assessment and psychometric IQ test results?\",\n",
    "        \"What is significantly associated with higher intelligent quotient (IQ) scores?\",\n",
    "        \"What would happen in a scenario where you lower the IQ of a person?\",\n",
    "        \"What are the potential applications of AI systems in different nursing care settings?\",\n",
    "        \"What is the TT100K dataset?\",\n",
    "        \"Are forms of narcissism (grandiose and vulnerable) related to objective intelligence?\",\n",
    "        \"Tell me about the practical implementation of Industrial Internet of Things over 5G\",\n",
    "        \"Tell me about End-to-End Automated License Plate Recognition System Using YOLO Based Vehicle and License Plate Detection with Vehicle Classification\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"What IQ is higher - 100 or 120?\",\n",
    "        \"What is the difference between IQ and EQ?\",\n",
    "    ],\n",
    "    \"answer_human\": [\n",
    "        \"Should deny the question as it is out of domain\",\n",
    "        \"Should deny the question as it is out of domain\",\n",
    "        \"Empathy and emotional intelligence are predictors of nurses' attitudes towards communication, and the cognitive dimension of attitude is a good predictor of the behavioural dimension of attitudes towards communication of nurses in both regression models and fuzzy-set qualitative comparative analysis.\",\n",
    "        \"Autism spectrum disorders (ASD) are characterized by persistent deficits in social communication and social interaction across contexts, and are associated with restricted patterns of behavior. The developmental quotient (DQ) is based on the developmental age and chronological age of children.\",\n",
    "        \"The Tsinghua-Tencent 100K (TT100K) traffic sign dataset. (It is a dataset for traffic sign detection, which contains 100,000 images with 224,024 annotated traffic signs.)\",\n",
    "        \"Electronic health records (EHRs) are digital records of health information. Electronic health record (EHR) was hailed as a major step towards making healthcare more transparent and accountable. All the developed nations digitised their health records which were meant to be safe, secure and could be accessed on demand. This was intended to benefit all stakeholders. However, the jury is still out if the EHR has been worth it. There have been incidences of data breaches despite cybersecurity checks and of manipulation compromising clinicians' integrity and patients' safety. EHRs have also been blamed for doctor burnout in overloading them with a largely avoidable administrative burden. The lack of interoperability amongst various EHR software systems is creating obstacles in seamless workflow.\",\n",
    "        \"The reviewed findings motivate new insights about how network topology and dynamics account for individual differences in g, represented by the Network Neuroscience Theory. According to this framework, g emerges from the small-world topology of brain networks and the dynamic reorganization of its community structure in the service of system-wide flexibility and adaptation.\",\n",
    "        \"The best fit between brain traits and degrees of intelligence among mammals is reached by a combination of the number of cortical neurons, neuron packing density, interneuronal distance and axonal conduction velocity--factors that determine general information processing capacity (IPC), as reflected by general intelligence. The highest IPC is found in humans, followed by the great apes, Old World and New World monkeys.\",\n",
    "        \"Intelligence is the ability to learn from experience and to adapt to, shape, and select environments. Intelligence as measured by (raw scores on) conventional standardized tests varies across the lifespan, and also across generations.\",\n",
    "        \"Fluid intelligence is related to capacity in memory as well as attention: Evidence from middle childhood and adulthood which was published on 22 August 2019 as compared to the other paper which was published in August 2022\",\n",
    "        \"No (Both forms of narcissism (grandiose and vulnerable) were unrelated to objective intelligence.)\",\n",
    "        \"Yes (Intellectually gifted children performed quicker than the average group for both mixed and single-trial blocks.)\",\n",
    "        \"In 1981, psychologist James Flynn noticed that IQ scores had risen streadily over nearly a century a staggering difference of 18 points over two generations. After a careful analysis, he concluded the cause to be culture. Society had become more intelligent-come to grips with bigger, more abstract ideas over time-and had made people smarter. This observation, combined with solid evidence that IQ scores are also not fixed within an individual, neatly dispels the idea of intelligence being an innate and fixed entity. While intelligence clearly has a biological component, it is best defined, as a set of continually developed skills.\",\n",
    "        \"The data indicates that a worker's age influences his/her capacity to work with method and order, and that workers with emotional exhaustion (a basic feature of burnout) have lower scores in method and order. Greater emotional exhaustion and greater depersonalization were related to lower personal accomplishment and greater burnout.\",\n",
    "        'The different types of intelligence are: 1. Naturalist Intelligence (\"Nature Smart\") 2. Musical Intelligence (\"Musical Smart\") 3. Logical-Mathematical Intelligence (Number/Reasoning Smart) 4. Existential Intelligence 5. Interpersonal Intelligence (People Smart) 6. Bodily-Kinesthetic Intelligence (\"Body Smart\") 7. Linguistic Intelligence (Word Smart) 8. Intra-personal Intelligence (Self Smart) 9. Spatial Intelligence (\"Picture Smart\") (Any of the points if listed are counted as valid answers)',\n",
    "        \"Some abreivations used in the field of intelligence in PubMed are: 1. IQ (Intelligence Quotient) 2. G (General Intelligence) 3. EI (Emotional Intelligence) 4. CQ (Cultural Intelligence) 5. SQ (Social Intelligence) 6. PQ (Political Intelligence) 7. AQ (Adversity Intelligence) 8. MQ (Moral Intelligence) 9. FQ (Financial Intelligence) 10. RQ (Rational Intelligence) 11. TQ (Technical Intelligence) 12. EQ (Emotional Quotient) 13. SQ (Social Quotient) 14. PQ (Political Quotient) 15. AQ (Adversity Quotient) 16. MQ (Moral Quotient) 17. FQ (Financial Quotient) 18. RQ (Rational Quotient) 19. TQ (Technical Quotient) (Any of the points if listed are counted as valid answers)\",\n",
    "        \"Here, we suggest that the loss of the external shell in cephalopods (i) caused a dramatic increase in predatory pressure, which in turn prevented the emergence of slow life histories, and (ii) allowed the exploitation of novel challenging niches, thus favouring the emergence of intelligence.\",\n",
    "        \"In the National Child Development Study, life-course variability in happiness over 18 years was significantly negatively associated with its mean level (happier individuals were more stable in their happiness, and it was not due to the ceiling effect), as well as childhood general intelligence and all Big Five personality factors (except for Agreeableness). In a multiple regression analysis, childhood general intelligence was the strongest predictor of life-course variability in life satisfaction, stronger than all Big Five personality factors, including Emotional stability. More intelligent individuals were significantly more stable in their happiness, and it was not entirely because: (1) they were more educated and wealthier (even though they were); (2) they were healthier (even though they were); (3) they were more stable in their marital status (even though they were); (4) they were happier (even though they were); (5) they were better able to assess their own happiness accurately (even though they were); or (6) they were better able to recall their previous responses more accurately or they were more honest in their survey responses (even though they were both). While I could exclude all of these alternative explanations, it ultimately remained unclear why more intelligent individuals were more stable in their happiness.\",\n",
    "        \"Our models show no direct link between diet and cognitive performance in old age; instead they are related via the lifelong-stable trait of intelligence. (No correct answer here)\",\n",
    "        \"No definitive answer here\",\n",
    "        \"Three themes emerged: the sensibility to engage EI capabilities in clinical contexts, motivation to actively engage with emotions in clinical decision-making and incorporating emotional and technical perspectives in decision-making.\",\n",
    "        \"To test this hypothesis, we administered the Learning Context Questionnaire to measure intellectual development. In addition, we administered the Intrinsic Motivation Inventory to assess our students' intrinsic motivation. Furthermore, we performed regression analyses between intellectual development with both intrinsic motivation and class performance. The results document a positive relationship among intellectual development, intrinsic motivation, and class performance for female students only. In sharp contrast, there was a negative relationship between intellectual development, intrinsic motivation, and class performance for male students. The slope comparisons documented significant differences in the slopes relating intellectual development, intrinsic motivation, and class performance between female and male students. Thus, female students with more sophisticated beliefs that knowledge is personally constructed, complex, and evolving had higher intrinsic motivation and class performance. In contrast, male students with the naive beliefs that the structure of knowledge is simple, absolute, and certain had higher levels of intrinsic motivation and class performance.\",\n",
    "        'From the paper \"What subject matter questions motivate the use of machine learning approaches compared to statistical models for probability prediction?\"',\n",
    "        \"No definitive answer here\",\n",
    "        \"25 September 2023\",\n",
    "        \"20 August 2021\",\n",
    "        \"United States of America\",\n",
    "        \"China\",\n",
    "        \"Education was rated by N = 71 experts as the most important cause of international ability differences. Genes were rated as the second most relevant factor but also had the highest variability in ratings. Culture, health, wealth, modernization, and politics were the next most important factors, whereas other factors such as geography, climate, test bias, and sampling error were less important.\",\n",
    "        \"Happiness is significantly associated with IQ. Those in the lowest IQ range (70-99) reported the lowest levels of happiness compared with the highest IQ group (120-129). Mediation analysis using the continuous IQ variable found dependency in activities of daily living, income, health and neurotic symptoms were strong mediators of the relationship, as they reduced the association between happiness and IQ by 50%.\",\n",
    "        \"Those with lower IQ are less happy than those with higher IQ. Interventions that target modifiable variables such as income (e.g. through enhancing education and employment opportunities) and neurotic symptoms (e.g. through better detection of mental health problems) may improve levels of happiness in the lower IQ groups.\",\n",
    "        \"No definitive answer as scenario based questions are usually hypothetical.\",\n",
    "        \"The Tsinghua-Tencent 100K (TT100K) traffic sign dataset. (It is a dataset for traffic sign detection, which contains 100,000 images with 224,024 annotated traffic signs.)\",\n",
    "        \"No (Both forms of narcissism (grandiose and vulnerable) were unrelated to objective intelligence.)\",\n",
    "        \"The next generation of mobile broadband communication, 5G, is seen as a driver for the industrial Internet of things (IIoT). The expected 5G-increased performance spanning across different indicators, flexibility to tailor the network to the needs of specific use cases, and the inherent security that offers guarantees both in terms of performance and data isolation have triggered the emergence of the concept of public network integrated non-public network (PNI-NPN) 5G networks. These networks might be a flexible alternative for the well-known (albeit mostly proprietary) Ethernet wired connections and protocols commonly used in the industry setting. With that in mind, this paper presents a practical implementation of IIoT over 5G composed of different infrastructure and application components. From the infrastructure perspective, the implementation includes a 5G Internet of things (IoT) end device that collects sensing data from shop floor assets and the surrounding environment and makes these data available over an industrial 5G Network. Application-wise, the implementation includes an intelligent assistant that consumes such data to generate valuable insights that allow for the sustainable operation of assets. These components have been tested and validated in a real shop floor environment at Bosch Termotecnologia (Bosch TT). Results show the potential of 5G as an enhancer of IIoT towards smarter, more sustainable, green, and environmentally friendly factories.\",\n",
    "        \"An accurate and robust Automatic License Plate Recognition (ALPR) method proves surprising versatility in an Intelligent Transportation and Surveillance (ITS) system. However, most of the existing approaches often use prior knowledge or fixed pre-and-post processing rules and are thus limited by poor generalization in complex real-life conditions. In this paper, we leverage a YOLO-based end-to-end generic ALPR pipeline for vehicle detection (VD), license plate (LP) detection and recognition without exploiting prior knowledge or additional steps in inference. We assess the whole ALPR pipeline, starting from vehicle detection to the LP recognition stage, including a vehicle classifier for emergency vehicles and heavy trucks. We used YOLO v2 in the initial stage of the pipeline and remaining stages are based on the state-of-the-art YOLO v4 detector with various data augmentation and generation techniques to obtain LP recognition accuracy on par with current proposed methods. To evaluate our approach, we used five public datasets from different regions, and we achieved an average recognition accuracy of 90.3% while maintaining an acceptable frames per second (FPS) on a low-end GPU.\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"120\",\n",
    "        \"IQ is the ability to learn, understand, and apply information. EQ is the ability to understand and manage your own emotions and those of others. (question comparing different types of intelligence)\",\n",
    "    ],\n",
    "    \"PMID\": [\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"29495095\",\n",
    "        \"26933939\",\n",
    "        \"36502047\",\n",
    "        \"32936099\",\n",
    "        \"29167088\",\n",
    "        \"26598734\",\n",
    "        \"22577301\",\n",
    "        \"35751918\",\n",
    "        \"31654584\",\n",
    "        \"24897910\",\n",
    "        \"27906516\",\n",
    "        \"32024740\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"30446408\",\n",
    "        \"24943404\",\n",
    "        \"23732046\",\n",
    "        \"23957184\",\n",
    "        \"29048766\",\n",
    "        \"26330034\",\n",
    "        \"24615759\",\n",
    "        \"\",\n",
    "        \"37749085\",\n",
    "        \"34186105\",\n",
    "        \"31766555\",\n",
    "        \"36429493\",\n",
    "        \"27047425\",\n",
    "        \"22998852\",\n",
    "        \"22998852\",\n",
    "        \"34847057\",\n",
    "        \"36502047\",\n",
    "        \"31654584\",\n",
    "        \"37299925\",\n",
    "        \"36502178\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5644c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_human</th>\n",
       "      <th>answer_chatgpt</th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Out of domain questions</td>\n",
       "      <td>How tall is the Golden Gate Bridge?</td>\n",
       "      <td>Should deny the question as it is out of domain</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Out of domain questions</td>\n",
       "      <td>Where is the Eiffel Tower located?</td>\n",
       "      <td>Should deny the question as it is out of domain</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In domain questions</td>\n",
       "      <td>What are the predictors of nurses' attitudes t...</td>\n",
       "      <td>Empathy and emotional intelligence are predict...</td>\n",
       "      <td></td>\n",
       "      <td>29495095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In domain questions</td>\n",
       "      <td>What is Autism Spectrum Disorder (ASD) charact...</td>\n",
       "      <td>Autism spectrum disorders (ASD) are characteri...</td>\n",
       "      <td></td>\n",
       "      <td>26933939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Query contains named entities that should be t...</td>\n",
       "      <td>What is the TT100K dataset?</td>\n",
       "      <td>The Tsinghua-Tencent 100K (TT100K) traffic sig...</td>\n",
       "      <td></td>\n",
       "      <td>36502047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Query contains named entities that should be t...</td>\n",
       "      <td>What is the full form of EHR? / Tell me about ...</td>\n",
       "      <td>Electronic health records (EHRs) are digital r...</td>\n",
       "      <td></td>\n",
       "      <td>32936099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Handle fully specified questions that might co...</td>\n",
       "      <td>Tell me about the recent neuroscience evidence...</td>\n",
       "      <td>The reviewed findings motivate new insights ab...</td>\n",
       "      <td></td>\n",
       "      <td>29167088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Handle fully specified questions that might co...</td>\n",
       "      <td>The best fit between brain traits and degrees ...</td>\n",
       "      <td>The best fit between brain traits and degrees ...</td>\n",
       "      <td></td>\n",
       "      <td>26598734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fully support both semantic search and lexicog...</td>\n",
       "      <td>(Semantic query) What is intelligence?</td>\n",
       "      <td>Intelligence is the ability to learn from expe...</td>\n",
       "      <td></td>\n",
       "      <td>22577301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fully support both semantic search and lexicog...</td>\n",
       "      <td>Lexicographical query) Which paper was publish...</td>\n",
       "      <td>Fluid intelligence is related to capacity in m...</td>\n",
       "      <td></td>\n",
       "      <td>35751918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                                        question_type  \\\n",
       "\u001b[1;36m1\u001b[0m                             Out of domain questions   \n",
       "\u001b[1;36m2\u001b[0m                             Out of domain questions   \n",
       "\u001b[1;36m3\u001b[0m                                 In domain questions   \n",
       "\u001b[1;36m4\u001b[0m                                 In domain questions   \n",
       "\u001b[1;36m5\u001b[0m   Query contains named entities that should be t\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m6\u001b[0m   Query contains named entities that should be t\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m7\u001b[0m   Handle fully specified questions that might co\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m8\u001b[0m   Handle fully specified questions that might co\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m9\u001b[0m   Fully support both semantic search and lexicog\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m10\u001b[0m  Fully support both semantic search and lexicog\u001b[33m...\u001b[0m   \n",
       "\n",
       "                                             question  \\\n",
       "\u001b[1;36m1\u001b[0m                 How tall is the Golden Gate Bridge?   \n",
       "\u001b[1;36m2\u001b[0m                  Where is the Eiffel Tower located?   \n",
       "\u001b[1;36m3\u001b[0m   What are the predictors of nurses' attitudes t\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m   What is Autism Spectrum Disorder \u001b[1m(\u001b[0mASD\u001b[1m)\u001b[0m charact\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                         What is the TT100K dataset?   \n",
       "\u001b[1;36m6\u001b[0m   What is the full form of EHR? \u001b[35m/\u001b[0m Tell me about \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m7\u001b[0m   Tell me about the recent neuroscience evidence\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m8\u001b[0m   The best fit between brain traits and degrees \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m9\u001b[0m              \u001b[1m(\u001b[0mSemantic query\u001b[1m)\u001b[0m What is intelligence?   \n",
       "\u001b[1;36m10\u001b[0m  Lexicographical query\u001b[1m)\u001b[0m Which paper was publish\u001b[33m...\u001b[0m   \n",
       "\n",
       "                                         answer_human answer_chatgpt      PMID  \n",
       "\u001b[1;36m1\u001b[0m     Should deny the question as it is out of domain                           \n",
       "\u001b[1;36m2\u001b[0m     Should deny the question as it is out of domain                           \n",
       "\u001b[1;36m3\u001b[0m   Empathy and emotional intelligence are predict\u001b[33m...\u001b[0m                 \u001b[1;36m29495095\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m   Autism spectrum disorders \u001b[1m(\u001b[0mASD\u001b[1m)\u001b[0m are characteri\u001b[33m...\u001b[0m                 \u001b[1;36m26933939\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m   The Tsinghua-Tencent 100K \u001b[1m(\u001b[0mTT100K\u001b[1m)\u001b[0m traffic sig\u001b[33m...\u001b[0m                 \u001b[1;36m36502047\u001b[0m  \n",
       "\u001b[1;36m6\u001b[0m   Electronic health records \u001b[1m(\u001b[0mEHRs\u001b[1m)\u001b[0m are digital r\u001b[33m...\u001b[0m                 \u001b[1;36m32936099\u001b[0m  \n",
       "\u001b[1;36m7\u001b[0m   The reviewed findings motivate new insights ab\u001b[33m...\u001b[0m                 \u001b[1;36m29167088\u001b[0m  \n",
       "\u001b[1;36m8\u001b[0m   The best fit between brain traits and degrees \u001b[33m...\u001b[0m                 \u001b[1;36m26598734\u001b[0m  \n",
       "\u001b[1;36m9\u001b[0m   Intelligence is the ability to learn from expe\u001b[33m...\u001b[0m                 \u001b[1;36m22577301\u001b[0m  \n",
       "\u001b[1;36m10\u001b[0m  Fluid intelligence is related to capacity in m\u001b[33m...\u001b[0m                 \u001b[1;36m35751918\u001b[0m  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.insert(loc=df.columns.get_loc(\"answer_human\") + 1, column=\"answer_chatgpt\", value=\"\")\n",
    "df.index += 1\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b29ebfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328cf18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:50:45] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag</span> <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">es/lazy_loader/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>: KedroDeprecationWarning: <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataSet'</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has been renamed to <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataset'</span>, and the alias will be removed in     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Kedro-Datasets <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           attr = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">getattr</span><span style=\"font-weight: bold\">(</span>submod, name<span style=\"font-weight: bold\">)</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:50:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag\u001b[0m \u001b]8;id=452004;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=763194;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35mes/lazy_loader/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m78\u001b[0m: KedroDeprecationWarning: \u001b[32m'CSVDataSet'\u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         has been renamed to \u001b[32m'CSVDataset'\u001b[0m, and the alias will be removed in     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Kedro-Datasets \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           attr = \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0msubmod, name\u001b[1m)\u001b[0m                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedroNLP                                                 <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedroNLP                                                 \u001b]8;id=659624;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=926498;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=648982;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=683722;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'run_viz'</span>                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                        \u001b]8;id=840800;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=987275;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "#Setting up the environment\n",
    "%reload_kedro /Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp\n",
    "\n",
    "# Set the working directory your Jupyter Notebook file\n",
    "notebook_directory = \"/Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp\"\n",
    "os.chdir(notebook_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/06_models/llama-2-7b-chat.Q4_K_M.gguf\n",
      "chroma_store\n"
     ]
    }
   ],
   "source": [
    "#The relative paths here have to match the paths used in the kedro folders\n",
    "absolute_path_1 = \"/Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp/data/06_models/llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "absolute_path_2 = \"/Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp/chroma_store\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the relative paths using os.path.join\n",
    "relative_path_1 = os.path.relpath(absolute_path_1, current_directory)\n",
    "relative_path_2 = os.path.relpath(absolute_path_2, current_directory)\n",
    "\n",
    "# Print or use the relative paths\n",
    "print(relative_path_1)\n",
    "print(relative_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0059e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:09:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedronlp                                                  <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:09:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedronlp                                                  \u001b]8;id=642828;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58024;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\u001b\\\u001b[2m365\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:10:01] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag</span> <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">es/lazy_loader/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>: KedroDeprecationWarning: <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataSet'</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has been renamed to <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataset'</span>, and the alias will be removed in     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Kedro-Datasets <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           attr = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">getattr</span><span style=\"font-weight: bold\">(</span>submod, name<span style=\"font-weight: bold\">)</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:10:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag\u001b[0m \u001b]8;id=604464;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=435066;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35mes/lazy_loader/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m78\u001b[0m: KedroDeprecationWarning: \u001b[32m'CSVDataSet'\u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         has been renamed to \u001b[32m'CSVDataset'\u001b[0m, and the alias will be removed in     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Kedro-Datasets \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           attr = \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0msubmod, name\u001b[1m)\u001b[0m                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: get_user_query_node: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_user_query</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span> -&gt; <span style=\"font-weight: bold\">[</span>user_query<span style=\"font-weight: bold\">]</span>    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: get_user_query_node: \u001b[1;35mget_user_query\u001b[0m\u001b[1m(\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m -> \u001b[1m[\u001b[0muser_query\u001b[1m]\u001b[0m    \u001b]8;id=989509;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=203021;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your question: Is Diarrhea a symptom of Dysarthria?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:10:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:10:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=892404;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=253317;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m1\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=930701;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=348537;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=397381;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241146;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:top_k_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:top_k_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m         \u001b]8;id=685372;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=408308;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=105497;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=425255;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: top_k_retrieval_node:                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">top_k_retrieval</span><span style=\"font-weight: bold\">([</span>user_query,params:top_k_params,params:modelling_params<span style=\"font-weight: bold\">])</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         -&gt; <span style=\"font-weight: bold\">[</span>top_k_docs<span style=\"font-weight: bold\">]</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: top_k_retrieval_node:                                        \u001b]8;id=121756;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=419687;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mtop_k_retrieval\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,params:top_k_params,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m  \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         -> \u001b[1m[\u001b[0mtop_k_docs\u001b[1m]\u001b[0m                                                            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectordb:<langchain_community.vectorstores.chroma.Chroma object at 0x19d0a50d0>, user_input:Is Diarrhea a symptom of Dysarthria?, number_docs_in_chroma:187838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:10:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:10:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=518589;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=28190;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m2\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=281584;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568180;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=75754;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=526164;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                     \u001b]8;id=623357;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418549;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=848655;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=150388;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: modelling_answer_node:                                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">modelling_answer</span><span style=\"font-weight: bold\">([</span>user_query,top_k_docs,params:modelling_params<span style=\"font-weight: bold\">])</span> -&gt;       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">[</span>llm_response<span style=\"font-weight: bold\">]</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: modelling_answer_node:                                       \u001b]8;id=823748;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=302646;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mmodelling_answer\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,top_k_docs,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m ->       \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0mllm_response\u001b[1m]\u001b[0m                                                             \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from data/06_models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: mem required  = 3891.36 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 159.32 MiB\n",
      "llama_new_context_with_model: max tensor size =   102.54 MiB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  3891.95 MiB, ( 3893.55 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1024.03 MiB, ( 4917.58 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   156.01 MiB, ( 5073.59 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: No, diarrhea is not a symptom of dysarthria.\n",
      "\n",
      "====================\n",
      "Sources:\n",
      "\n",
      "Authors: Pam Enderby\n",
      "Title: Disorders of communication: dysarthria.\n",
      "Year: 2013\n",
      "____________________\n",
      "\n",
      "Authors: Elien De Cock, Kristine Oostra, Lisa Bliki, Anne-Sophie Volkaerts, Dimitri Hemelsoet, Veerle De Herdt, Katja Batens\n",
      "Title: Dysarthria following acute ischemic stroke: Prospective evaluation of characteristics, type and severity.\n",
      "Year: 2021\n",
      "____________________\n",
      "\n",
      "Authors: Kristie A Spencer, Katherine A Brown\n",
      "Title: Dysarthria following Stroke.\n",
      "Year: 2018\n",
      "____________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    8503.90 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    21 runs   (    0.60 ms per token,  1665.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9903.80 ms /   645 tokens (   15.35 ms per token,    65.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1660.36 ms /    20 runs   (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =   11858.95 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:10:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'llm_response'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:10:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'llm_response'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                      \u001b]8;id=72310;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921164;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m3\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=237046;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=936990;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Pipeline execution completed successfully.                               <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Pipeline execution completed successfully.                               \u001b]8;id=57017;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\u001b\\\u001b[2mrunner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=226385;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(pipeline_name=\"modelling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5362aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import builtins\n",
    "import os\n",
    "\n",
    "#function to simulate user input with evaluation questions\n",
    "@contextmanager\n",
    "def insert(answer: str):\n",
    "    try:\n",
    "        original_input = builtins.input\n",
    "        \n",
    "        def mock_input(*args, **kwargs):\n",
    "            return answer\n",
    "        \n",
    "        builtins.input = mock_input\n",
    "        yield\n",
    "    \n",
    "    finally:\n",
    "        builtins.input = original_input\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbac98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:50:57] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag</span> <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">es/lazy_loader/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>: KedroDeprecationWarning: <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataSet'</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has been renamed to <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataset'</span>, and the alias will be removed in     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Kedro-Datasets <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           attr = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">getattr</span><span style=\"font-weight: bold\">(</span>submod, name<span style=\"font-weight: bold\">)</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:50:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag\u001b[0m \u001b]8;id=529016;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431662;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35mes/lazy_loader/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m78\u001b[0m: KedroDeprecationWarning: \u001b[32m'CSVDataSet'\u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         has been renamed to \u001b[32m'CSVDataset'\u001b[0m, and the alias will be removed in     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Kedro-Datasets \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           attr = \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0msubmod, name\u001b[1m)\u001b[0m                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedroNLP                                                 <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedroNLP                                                 \u001b]8;id=334432;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=617183;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=525902;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=452414;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'run_viz'</span>                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                        \u001b]8;id=839883;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=442637;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedronlp                                                  <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedronlp                                                  \u001b]8;id=716053;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=248230;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\u001b\\\u001b[2m365\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:03] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag</span> <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">es/lazy_loader/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>: KedroDeprecationWarning: <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataSet'</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has been renamed to <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataset'</span>, and the alias will be removed in     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Kedro-Datasets <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           attr = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">getattr</span><span style=\"font-weight: bold\">(</span>submod, name<span style=\"font-weight: bold\">)</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag\u001b[0m \u001b]8;id=692391;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=542070;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35mes/lazy_loader/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m78\u001b[0m: KedroDeprecationWarning: \u001b[32m'CSVDataSet'\u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         has been renamed to \u001b[32m'CSVDataset'\u001b[0m, and the alias will be removed in     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Kedro-Datasets \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           attr = \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0msubmod, name\u001b[1m)\u001b[0m                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: get_user_query_node: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_user_query</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span> -&gt; <span style=\"font-weight: bold\">[</span>user_query<span style=\"font-weight: bold\">]</span>    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: get_user_query_node: \u001b[1;35mget_user_query\u001b[0m\u001b[1m(\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m -> \u001b[1m[\u001b[0muser_query\u001b[1m]\u001b[0m    \u001b]8;id=758901;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=322047;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=303188;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=215246;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m1\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=548462;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552594;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=278759;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703967;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:top_k_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:top_k_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m         \u001b]8;id=533297;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=617205;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=227132;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=912997;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: top_k_retrieval_node:                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">top_k_retrieval</span><span style=\"font-weight: bold\">([</span>user_query,params:top_k_params,params:modelling_params<span style=\"font-weight: bold\">])</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         -&gt; <span style=\"font-weight: bold\">[</span>top_k_docs<span style=\"font-weight: bold\">]</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: top_k_retrieval_node:                                        \u001b]8;id=515839;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=540234;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mtop_k_retrieval\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,params:top_k_params,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m  \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         -> \u001b[1m[\u001b[0mtop_k_docs\u001b[1m]\u001b[0m                                                            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectordb:<langchain_community.vectorstores.chroma.Chroma object at 0x19f87ad50>, user_input:Is Coughing a symptom of Dysarthria?, number_docs_in_chroma:187838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=269715;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=376427;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m2\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=859574;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=629536;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=837967;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51703;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                     \u001b]8;id=100476;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213973;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=855740;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=573519;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: modelling_answer_node:                                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">modelling_answer</span><span style=\"font-weight: bold\">([</span>user_query,top_k_docs,params:modelling_params<span style=\"font-weight: bold\">])</span> -&gt;       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">[</span>llm_response<span style=\"font-weight: bold\">]</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: modelling_answer_node:                                       \u001b]8;id=892721;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=642367;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mmodelling_answer\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,top_k_docs,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m ->       \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0mllm_response\u001b[1m]\u001b[0m                                                             \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from data/06_models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: mem required  = 3891.36 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 159.32 MiB\n",
      "llama_new_context_with_model: max tensor size =   102.54 MiB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  3891.95 MiB, ( 3893.55 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1024.03 MiB, ( 4917.58 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   156.01 MiB, ( 5073.59 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately I have no information on your question at hand. \n",
      "              This might be the case since I only consider abstracts from Pubmed that match the keyword intelligence. \n",
      "              Furthermore, I only consider papers published between 2013 and 2023. \n",
      "              In case your question matches these requirements please try reformulating your query\n",
      "\n",
      "\n",
      "====================\n",
      "Sources:\n",
      "\n",
      "Authors: Woo-Jung Song, Christopher K M Hui, James H Hull, Surinder S Birring, Lorcan McGarvey, Stuart B Mazzone, Kian Fan Chung\n",
      "Title: Confronting COVID-19-associated cough and the post-COVID syndrome: role of viral neurotropism, neuroinflammation, and neuroimmune responses.\n",
      "Year: 2021\n",
      "____________________\n",
      "\n",
      "Authors: Kawther S Alqudaihi, Nida Aslam, Irfan Ullah Khan, Abdullah M Almuhaideb, Shikah J Alsunaidi, Nehad M Abdel Rahman Ibrahim, Fahd A Alhaidari, Fatema S Shaikh, Yasmine M Alsenbel, Dima M Alalharith, Hajar M Alharthi, Wejdan M Alghamdi, Mohammed S Alshahrani\n",
      "Title: Cough Sound Detection and Diagnosis Using Artificial Intelligence Techniques: Challenges and Opportunities.\n",
      "Year: 2021\n",
      "____________________\n",
      "\n",
      "Authors: Vladimir Despotovic, Muhannad Ismael, Maël Cornil, Roderick Mc Call, Guy Fagherazzi\n",
      "Title: Detection of COVID-19 from voice, cough and breathing patterns: Dataset and preliminary results.\n",
      "Year: 2021\n",
      "____________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   11198.19 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     1 runs   (    0.62 ms per token,  1612.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14636.39 ms /   877 tokens (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   14661.48 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:23] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'llm_response'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'llm_response'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                      \u001b]8;id=73926;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=354445;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m3\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=524315;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=128272;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Pipeline execution completed successfully.                               <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Pipeline execution completed successfully.                               \u001b]8;id=924061;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\u001b\\\u001b[2mrunner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=623899;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'llm_response'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                   <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'llm_response'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                   \u001b]8;id=30470;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=297768;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   response                                 query  \\\n",
      "0       NaN  Is Coughing a symptom of Dysarthria?   \n",
      "1       NaN  Is Coughing a symptom of Dysarthria?   \n",
      "2       NaN  Is Coughing a symptom of Dysarthria?   \n",
      "\n",
      "                                              Author  \\\n",
      "0  Woo-Jung Song, Christopher K M Hui, James H Hu...   \n",
      "1  Kawther S Alqudaihi, Nida Aslam, Irfan Ullah K...   \n",
      "2  Vladimir Despotovic, Muhannad Ismael, Maël Cor...   \n",
      "\n",
      "                                               Title  Year  \n",
      "0  Confronting COVID-19-associated cough and the ...  2021  \n",
      "1  Cough Sound Detection and Diagnosis Using Arti...  2021  \n",
      "2  Detection of COVID-19 from voice, cough and br...  2021  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:24] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag</span> <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">es/lazy_loader/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">__init__.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>: KedroDeprecationWarning: <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataSet'</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has been renamed to <span style=\"color: #008000; text-decoration-color: #008000\">'CSVDataset'</span>, and the alias will be removed in     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Kedro-Datasets <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           attr = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">getattr</span><span style=\"font-weight: bold\">(</span>submod, name<span style=\"font-weight: bold\">)</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packag\u001b[0m \u001b]8;id=287224;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=653140;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35mes/lazy_loader/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m78\u001b[0m: KedroDeprecationWarning: \u001b[32m'CSVDataSet'\u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         has been renamed to \u001b[32m'CSVDataset'\u001b[0m, and the alias will be removed in     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Kedro-Datasets \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           attr = \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0msubmod, name\u001b[1m)\u001b[0m                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedroNLP                                                 <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedroNLP                                                 \u001b]8;id=728759;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=798631;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=575347;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=646096;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'run_viz'</span>                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                        \u001b]8;id=168794;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=904550;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/ipython/__init__.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project kedronlp                                                  <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project kedronlp                                                  \u001b]8;id=682985;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=982457;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/framework/session/session.py#365\u001b\\\u001b[2m365\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: get_user_query_node: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_user_query</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span> -&gt; <span style=\"font-weight: bold\">[</span>user_query<span style=\"font-weight: bold\">]</span>    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: get_user_query_node: \u001b[1;35mget_user_query\u001b[0m\u001b[1m(\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m -> \u001b[1m[\u001b[0muser_query\u001b[1m]\u001b[0m    \u001b]8;id=300495;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=42949;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=157147;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=359783;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m1\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=353774;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=657694;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=582563;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=512416;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:top_k_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:top_k_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m         \u001b]8;id=505798;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=142244;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=964586;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=632388;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: top_k_retrieval_node:                                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">top_k_retrieval</span><span style=\"font-weight: bold\">([</span>user_query,params:top_k_params,params:modelling_params<span style=\"font-weight: bold\">])</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         -&gt; <span style=\"font-weight: bold\">[</span>top_k_docs<span style=\"font-weight: bold\">]</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: top_k_retrieval_node:                                        \u001b]8;id=498084;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=493568;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mtop_k_retrieval\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,params:top_k_params,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m  \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         -> \u001b[1m[\u001b[0mtop_k_docs\u001b[1m]\u001b[0m                                                            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectordb:<langchain_community.vectorstores.chroma.Chroma object at 0x19eaccb10>, user_input:Is Diarrhea a symptom of Dysarthria?, number_docs_in_chroma:187838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=24364;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=77264;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m2\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=132976;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=409642;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span> <span style=\"font-weight: bold\">(</span>TextDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'user_query'\u001b[0m \u001b[1m(\u001b[0mTextDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=661922;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=15181;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'top_k_docs'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'top_k_docs'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                     \u001b]8;id=480992;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=387601;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:modelling_params'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:modelling_params'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m     \u001b]8;id=988262;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=907944;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running node: modelling_answer_node:                                       <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">331</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">modelling_answer</span><span style=\"font-weight: bold\">([</span>user_query,top_k_docs,params:modelling_params<span style=\"font-weight: bold\">])</span> -&gt;       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">[</span>llm_response<span style=\"font-weight: bold\">]</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running node: modelling_answer_node:                                       \u001b]8;id=531948;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=481168;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/pipeline/node.py#331\u001b\\\u001b[2m331\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mmodelling_answer\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0muser_query,top_k_docs,params:modelling_params\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m ->       \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0mllm_response\u001b[1m]\u001b[0m                                                             \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from data/06_models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: mem required  = 3891.36 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 159.32 MiB\n",
      "llama_new_context_with_model: max tensor size =   102.54 MiB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  3891.95 MiB, ( 3893.61 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1024.03 MiB, ( 4917.64 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   156.01 MiB, ( 5073.66 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: No, diarrhea is not a symptom of dysarthria.\n",
      "\n",
      "====================\n",
      "Sources:\n",
      "\n",
      "Authors: Pam Enderby\n",
      "Title: Disorders of communication: dysarthria.\n",
      "Year: 2013\n",
      "____________________\n",
      "\n",
      "Authors: Elien De Cock, Kristine Oostra, Lisa Bliki, Anne-Sophie Volkaerts, Dimitri Hemelsoet, Veerle De Herdt, Katja Batens\n",
      "Title: Dysarthria following acute ischemic stroke: Prospective evaluation of characteristics, type and severity.\n",
      "Year: 2021\n",
      "____________________\n",
      "\n",
      "Authors: Kristie A Spencer, Katherine A Brown\n",
      "Title: Dysarthria following Stroke.\n",
      "Year: 2018\n",
      "____________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6770.36 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    21 runs   (    0.56 ms per token,  1774.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8173.12 ms /   645 tokens (   12.67 ms per token,    78.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1692.65 ms /    20 runs   (   84.63 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =   10137.96 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/13/24 15:51:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving data to <span style=\"color: #008000; text-decoration-color: #008000\">'llm_response'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/13/24 15:51:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving data to \u001b[32m'llm_response'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                      \u001b]8;id=138017;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=771820;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#541\u001b\\\u001b[2m541\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> tasks                                     <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sequential_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed \u001b[1;36m3\u001b[0m out of \u001b[1;36m3\u001b[0m tasks                                     \u001b]8;id=121482;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py\u001b\\\u001b[2msequential_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=908449;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/sequential_runner.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Pipeline execution completed successfully.                               <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Pipeline execution completed successfully.                               \u001b]8;id=619825;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py\u001b\\\u001b[2mrunner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=563174;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/runner/runner.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'llm_response'</span> <span style=\"font-weight: bold\">(</span>CSVDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                   <a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'llm_response'\u001b[0m \u001b[1m(\u001b[0mCSVDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                   \u001b]8;id=926632;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=592839;file:///Users/Kenneth/opt/anaconda3/envs/pubMedNLP/lib/python3.11/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            response  \\\n",
      "0  \\nAnswer: No, diarrhea is not a symptom of dys...   \n",
      "1  \\nAnswer: No, diarrhea is not a symptom of dys...   \n",
      "2  \\nAnswer: No, diarrhea is not a symptom of dys...   \n",
      "\n",
      "                                  query  \\\n",
      "0  Is Diarrhea a symptom of Dysarthria?   \n",
      "1  Is Diarrhea a symptom of Dysarthria?   \n",
      "2  Is Diarrhea a symptom of Dysarthria?   \n",
      "\n",
      "                                              Author  \\\n",
      "0                                        Pam Enderby   \n",
      "1  Elien De Cock, Kristine Oostra, Lisa Bliki, An...   \n",
      "2               Kristie A Spencer, Katherine A Brown   \n",
      "\n",
      "                                               Title  Year  \n",
      "0            Disorders of communication: dysarthria.  2013  \n",
      "1  Dysarthria following acute ischemic stroke: Pr...  2021  \n",
      "2                       Dysarthria following Stroke.  2018  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "# Assuming you have a list of questions\n",
    "questions = [\"Is Coughing a symptom of Dysarthria?\", \"Is Diarrhea a symptom of Dysarthria?\"]\n",
    "\n",
    "for question in questions:\n",
    "    with insert(question):\n",
    "        %reload_kedro /Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp\n",
    "        # Set the working directory to the Jupyter Notebook file\n",
    "        notebook_directory = \"/Users/Kenneth/PycharmProjects/pubMedNLP/kedronlp\"\n",
    "        os.chdir(notebook_directory)\n",
    "        response = session.run(pipeline_name=\"modelling\")\n",
    "        \n",
    "        # Load response from kedro into jupyter notebook \n",
    "        df = pd.DataFrame(catalog.load('llm_response'))\n",
    "        print(df.head(3))\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame containing all the responses\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a52bba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>query</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Is Coughing a symptom of Dysarthria?</td>\n",
       "      <td>Woo-Jung Song, Christopher K M Hui, James H Hu...</td>\n",
       "      <td>Confronting COVID-19-associated cough and the ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Is Coughing a symptom of Dysarthria?</td>\n",
       "      <td>Kawther S Alqudaihi, Nida Aslam, Irfan Ullah K...</td>\n",
       "      <td>Cough Sound Detection and Diagnosis Using Arti...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Is Coughing a symptom of Dysarthria?</td>\n",
       "      <td>Vladimir Despotovic, Muhannad Ismael, Maël Cor...</td>\n",
       "      <td>Detection of COVID-19 from voice, cough and br...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nAnswer: No, diarrhea is not a symptom of dys...</td>\n",
       "      <td>Is Diarrhea a symptom of Dysarthria?</td>\n",
       "      <td>Pam Enderby</td>\n",
       "      <td>Disorders of communication: dysarthria.</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nAnswer: No, diarrhea is not a symptom of dys...</td>\n",
       "      <td>Is Diarrhea a symptom of Dysarthria?</td>\n",
       "      <td>Elien De Cock, Kristine Oostra, Lisa Bliki, An...</td>\n",
       "      <td>Dysarthria following acute ischemic stroke: Pr...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nAnswer: No, diarrhea is not a symptom of dys...</td>\n",
       "      <td>Is Diarrhea a symptom of Dysarthria?</td>\n",
       "      <td>Kristie A Spencer, Katherine A Brown</td>\n",
       "      <td>Dysarthria following Stroke.</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                                            response  \\\n",
       "\u001b[1;36m0\u001b[0m                                                NaN   \n",
       "\u001b[1;36m1\u001b[0m                                                NaN   \n",
       "\u001b[1;36m2\u001b[0m                                                NaN   \n",
       "\u001b[1;36m3\u001b[0m  \\nAnswer: No, diarrhea is not a symptom of dys\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m  \\nAnswer: No, diarrhea is not a symptom of dys\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m  \\nAnswer: No, diarrhea is not a symptom of dys\u001b[33m...\u001b[0m   \n",
       "\n",
       "                                  query  \\\n",
       "\u001b[1;36m0\u001b[0m  Is Coughing a symptom of Dysarthria?   \n",
       "\u001b[1;36m1\u001b[0m  Is Coughing a symptom of Dysarthria?   \n",
       "\u001b[1;36m2\u001b[0m  Is Coughing a symptom of Dysarthria?   \n",
       "\u001b[1;36m3\u001b[0m  Is Diarrhea a symptom of Dysarthria?   \n",
       "\u001b[1;36m4\u001b[0m  Is Diarrhea a symptom of Dysarthria?   \n",
       "\u001b[1;36m5\u001b[0m  Is Diarrhea a symptom of Dysarthria?   \n",
       "\n",
       "                                              Author  \\\n",
       "\u001b[1;36m0\u001b[0m  Woo-Jung Song, Christopher K M Hui, James H Hu\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m  Kawther S Alqudaihi, Nida Aslam, Irfan Ullah K\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m  Vladimir Despotovic, Muhannad Ismael, Maël Cor\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                        Pam Enderby   \n",
       "\u001b[1;36m4\u001b[0m  Elien De Cock, Kristine Oostra, Lisa Bliki, An\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m               Kristie A Spencer, Katherine A Brown   \n",
       "\n",
       "                                               Title  Year  \n",
       "\u001b[1;36m0\u001b[0m  Confronting COVID-\u001b[1;36m19\u001b[0m-associated cough and the \u001b[33m...\u001b[0m  \u001b[1;36m2021\u001b[0m  \n",
       "\u001b[1;36m1\u001b[0m  Cough Sound Detection and Diagnosis Using Arti\u001b[33m...\u001b[0m  \u001b[1;36m2021\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m  Detection of COVID-\u001b[1;36m19\u001b[0m from voice, cough and br\u001b[33m...\u001b[0m  \u001b[1;36m2021\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m            Disorders of communication: dysarthria.  \u001b[1;36m2013\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m  Dysarthria following acute ischemic stroke: Pr\u001b[33m...\u001b[0m  \u001b[1;36m2021\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m                       Dysarthria following Stroke.  \u001b[1;36m2018\u001b[0m  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6481b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (kedronlp)",
   "language": "python",
   "name": "kedro_kedronlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
